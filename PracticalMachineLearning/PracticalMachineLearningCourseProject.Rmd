---
title: "Practical Machine Learning Course Project"
author: "Kurt Fitz"
date: "December 5, 2020"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## This document is the final project in the Coursera Practical Machine Learning course.
### Executive Summary
Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement â€“ a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. The goal of this project is to use data collected from accelerometers on the belt, forearm, arm, and dumbell of 6 participants to classify whether barbell lifts were done correctly or not.

### Data Loading and Cleaning
Load the data and remove variables with near zero variance, mostly NA values, and columns not related to prediction data.
```{r}
#Load the dependencies
library(caret)
library(e1071)
library(rpart)
library(rpart.plot)

#Read the data into memory
trainUrl<- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl<- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"

trainingData <- read.csv(url(trainUrl))
testData <- read.csv(url(testUrl))

dim(trainingData)
dim(testData)

# remove any variables with near zero variance
nzv <- nearZeroVar(trainingData)

trainingSet <- trainingData[, -nzv]
testingSet <- testData[, -nzv]

dim(trainingSet)
dim(testingSet)

# remove variables that are mostly NA
naCol <- sapply(trainingSet, function(x) mean(is.na(x))) > 0.95

trainingSet <- trainingSet[,naCol==FALSE]
testingSet  <- testingSet[,naCol==FALSE]

dim(trainingSet)
dim(testingSet)

# remove first seven variables, as they have no predictive value.
trainingSet <- trainingSet[, (8:59)]
testingSet  <- testingSet[, (8:59)]

dim(trainingSet)
dim(testingSet)

#convert classe column to factor variable for confusionMatrix compatability.
trainingSet$classe <- as.factor(trainingSet$classe)
testingSet$classe <- as.factor(testingSet$classe)

#partition data set
inTrain <- createDataPartition(trainingSet$classe, p=0.6, list=FALSE)

training <- trainingSet[inTrain,]
testing <- trainingSet[-inTrain,]
```

### Modeling

#### Gradient Boosting Model
```{r}
gbm_fit <- train(classe ~., data=training, method="gbm", verbose=FALSE)

gbm_fit$finalModel

```
Prediction using the GBM model
```{r}
gbm_predict <- predict(gbm_fit, testing)

gbm_predict_confMatrix <- confusionMatrix(gbm_predict, factor(testing$classe))

gbm_predict_confMatrix

```
Resulting plot
```{r}
plot(gbm_predict_confMatrix$table, col=gbm_predict_confMatrix$byClass, main="Grad Boosting")

```



#### Random Forest Model
```{r}
rf_fit <- train(classe ~., data=training, method="rf", ntree=125)

```
Prediction using the Random Forest Model
```{r}
rf_predict <- predict(rf_fit, testing)

rf_predict_confMatrix <- confusionMatrix(rf_predict, factor(testing$classe))

rf_predict_confMatrix
```
Resulting Plot
```{r}
plot(rf_predict_confMatrix$table, col=rf_predict_confMatrix$byClass,
     main=paste("Random Forest Accuracy",
                round(rf_predict_confMatrix$overall['Accuracy'],
                      4)))

``` 

#### Decision Tree Model
```{r}
#set.seed(3344)
dt_fit <- train(classe ~., data=training, method="rpart")

```

Prediction using the trained decision tree. 
```{r}
dt_predict <- predict(dt_fit, testing)

dt_confMatrix <- confusionMatrix(dt_predict, factor(testing$classe))

dt_confMatrix

```
Result Plot
```{r}
rpart.plot(dt_fit$finalModel, roundint=FALSE)
```

### Conclusion
After analyzing the results of the above three models, it appears that the Random Forest model is the most accurate for predicting 
whether the exercises were performed correctly.

### Applying Model to Test Data
final_rf_predict <- predict(rf_fit, testing)
finale_rf_predict
